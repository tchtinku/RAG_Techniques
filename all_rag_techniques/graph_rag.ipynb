{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRAG: Graph-Enhanced Retrieval-Augmented Generation\n",
    "\n",
    "#### Overview\n",
    "\n",
    "###### GraphRAG is an advanced question-answering system that combines the power of graph-based knowledge representation with retrieval-augmented generation. It processes input documents to create a rich knowledge graph, which is then used to enhance the retrieval and generation of answers to user queries. The system leverages natural language processing, machine learning, and graph theory to provide more accurate and contextually relevant responses.\n",
    "\n",
    "#### Motivation\n",
    "###### Traditional retrieval-augmented generation systems often struggle with maintaining context over long documents and making connections between related pieces of information. GraphRAG addresses these limitations by:\n",
    "\n",
    "###### Representing knowledge as an interconnected graph, allowing for better preservation of relationships between concepts.\n",
    "###### Enabling more intelligent traversal of information during the query process.\n",
    "###### Providing a visual representation of how information is connected and accessed during the answering process.\n",
    "\n",
    "#### Key Components\n",
    "###### DocumentProcessor: Handles the initial processing of input documents, creating text chunks and embeddings.\n",
    "\n",
    "###### KnowledgeGraph: Constructs a graph representation of the processed documents, where nodes represent text chunks and edges represent relationships between them.\n",
    "\n",
    "###### QueryEngine: Manages the process of answering user queries by leveraging the knowledge graph and vector store.\n",
    "\n",
    "###### Visualizer: Creates a visual representation of the graph and the traversal path taken to answer a query.\n",
    "\n",
    "#### Method Details\n",
    "###### Document Processing:\n",
    "\n",
    "###### Input documents are split into manageable chunks.\n",
    "###### Each chunk is embedded using a language model.\n",
    "###### A vector store is created from these embeddings for efficient similarity search.\n",
    "\n",
    "#### Knowledge Graph Construction:\n",
    "\n",
    "###### Graph nodes are created for each text chunk.\n",
    "###### Concepts are extracted from each chunk using a combination of NLP techniques and language models.\n",
    "###### Extracted concepts are lemmatized to improve matching.\n",
    "###### Edges are added between nodes based on semantic similarity and shared concepts.\n",
    "###### Edge weights are calculated to represent the strength of relationships.\n",
    "\n",
    "#### Query Processing:\n",
    "\n",
    "###### The user query is embedded and used to retrieve relevant documents from the vector store.\n",
    "###### A priority queue is initialized with the nodes corresponding to the most relevant documents.\n",
    "###### The system employs a Dijkstra-like algorithm to traverse the knowledge graph:\n",
    "###### Nodes are explored in order of their priority (strength of connection to the query).\n",
    "###### For each explored node:\n",
    "###### Its content is added to the context.\n",
    "###### The system checks if the current context provides a complete answer.\n",
    "###### If the answer is incomplete:\n",
    "###### The node's concepts are processed and added to a set of visited concepts.\n",
    "###### Neighboring nodes are explored, with their priorities updated based on edge weights.\n",
    "###### Nodes are added to the priority queue if a stronger connection is found.\n",
    "###### This process continues until a complete answer is found or the priority queue is exhausted.\n",
    "###### If no complete answer is found after traversing the graph, the system generates a final answer using the accumulated context and a large language model.\n",
    "\n",
    "#### Visualization:\n",
    "\n",
    "###### The knowledge graph is visualized with nodes representing text chunks and edges representing relationships.\n",
    "###### Edge colors indicate the strength of relationships (weights).\n",
    "###### The traversal path taken to answer a query is highlighted with curved, dashed arrows.\n",
    "###### Start and end nodes of the traversal are distinctly colored for easy identification.\n",
    "###### Benefits of This Approach\n",
    "###### Improved Context Awareness: By representing knowledge as a graph, the system can maintain better context and make connections across different parts of the input documents.\n",
    "\n",
    "###### Enhanced Retrieval: The graph structure allows for more intelligent retrieval of information, going beyond simple keyword matching.\n",
    "\n",
    "###### Explainable Results: The visualization of the graph and traversal path provides insight into how the system arrived at its answer, improving transparency and trust.\n",
    "\n",
    "###### Flexible Knowledge Representation: The graph structure can easily incorporate new information and relationships as they become available.\n",
    "\n",
    "###### Efficient Information Traversal: The weighted edges in the graph allow the system to prioritize the most relevant information pathways when answering queries.\n",
    "\n",
    "###### Conclusion\n",
    "###### GraphRAG represents a significant advancement in retrieval-augmented generation systems. By incorporating a graph-based knowledge representation and intelligent traversal mechanisms, it offers improved context awareness, more accurate retrieval, and enhanced explainability. The system's ability to visualize its decision-making process provides valuable insights into its operation, making it a powerful tool for both end-users and developers. As natural language processing and graph-based AI continue to evolve, systems like GraphRAG pave the way for more sophisticated and capable question-answering technologies.\n",
    "\n",
    "#### Import relevant libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Tuple, Dict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import spacy\n",
    "import heapq\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from spacy.cli import download\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the document processor class"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
