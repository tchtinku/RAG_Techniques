{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Indices in Document Retrieval\n",
    "\n",
    "#### Overview\n",
    "###### This code implements a Hierarchical Indexing system for document retrieval, utilizing two levels of encoding: document-level summaries and detailed chunks. This approach aims to improve the efficiency and relevance of information retrieval by first identifying relevant document sections through summaries, then drilling down to specific details within those sections.\n",
    "\n",
    "#### Motivation\n",
    "###### Traditional flat indexing methods can struggle with large documents or corpus, potentially missing context or returning irrelevant information. Hierarchical indexing addresses this by creating a two-tier search system, allowing for more efficient and context-aware retrieval.\n",
    "\n",
    "#### Key Components\n",
    "###### PDF processing and text chunking\n",
    "###### Asynchronous document summarization using OpenAI's GPT-4\n",
    "###### Vector store creation for both summaries and detailed chunks using FAISS and OpenAI embeddings\n",
    "###### Custom hierarchical retrieval function\n",
    "\n",
    "#### Method Details\n",
    "###### Document Preprocessing and Encoding\n",
    "###### The PDF is loaded and split into documents (likely by page).\n",
    "###### Each document is summarized asynchronously using GPT-4.\n",
    "###### The original documents are also split into smaller, detailed chunks.\n",
    "###### Two separate vector stores are created:\n",
    "###### One for document-level summaries\n",
    "###### One for detailed chunks\n",
    "###### Asynchronous Processing and Rate Limiting\n",
    "###### The code uses asynchronous programming (asyncio) to improve efficiency.\n",
    "###### Implements batching and exponential backoff to handle API rate limits.\n",
    "\n",
    "#### Hierarchical Retrieval\n",
    "###### The retrieve_hierarchical function implements the two-tier search:\n",
    "\n",
    "###### It first searches the summary vector store to identify relevant document sections.\n",
    "###### For each relevant summary, it then searches the detailed chunk vector store, filtering by the corresponding page number.\n",
    "###### This approach ensures that detailed information is retrieved only from the most relevant document sections.\n",
    "\n",
    "#### Benefits of this Approach\n",
    "###### Improved Retrieval Efficiency: By first searching summaries, the system can quickly identify relevant document sections without processing all detailed chunks.\n",
    "###### Better Context Preservation: The hierarchical approach helps maintain the broader context of retrieved information.\n",
    "###### Scalability: This method is particularly beneficial for large documents or corpus, where flat searching might be inefficient or miss important context.\n",
    "###### Flexibility: The system allows for adjusting the number of summaries and chunks retrieved, enabling fine-tuning for different use cases.\n",
    "\n",
    "#### Implementation Details\n",
    "###### Asynchronous Programming: Utilizes Python's asyncio for efficient I/O operations and API calls.\n",
    "###### Rate Limit Handling: Implements batching and exponential backoff to manage API rate limits effectively.\n",
    "###### Persistent Storage: Saves the generated vector stores locally to avoid unnecessary recomputation.\n",
    "\n",
    "#### Conclusion\n",
    "###### Hierarchical indexing represents a sophisticated approach to document retrieval, particularly suitable for large or complex document sets. By leveraging both high-level summaries and detailed chunks, it offers a balance between broad context understanding and specific information retrieval. This method has potential applications in various fields requiring efficient and context-aware information retrieval, such as legal document analysis, academic research, or large-scale content management systems.\n",
    "\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize.chain import Document\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) #Add the parent directory to the path since we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evaluate_rag import *\n",
    "from helper_functions import encode_pdf, encode_from_string\n",
    "\n",
    "#Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Set the OpenAI API key environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Document Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to encode to both summary & chunk levels, sharing the page metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "async def encode_pdf_hierarchical(path, chunk_size=1000, chunk_overlap=200, is_string=False):\n",
    "   \"\"\"\n",
    "   Asynchronously encodes a PDF book into a hierarchical vector store using OpenAI embeddings\n",
    "   Includes rate limit handling with exponential backoff\n",
    "\n",
    "   Args:\n",
    "      path: The path to the PDF file\n",
    "      chunk_size: The desired size of each text chunk\n",
    "      chunk_overlap: The amount of overlap between consecutive chunks\n",
    "\n",
    "   Returns:\n",
    "      A tuple containing two FAISS vector stores:\n",
    "      1. Document level summaries\n",
    "      2. Detailed chunks\n",
    "   \"\"\"\n",
    "\n",
    "   # Load PDF documents\n",
    "   if not is_string:\n",
    "      loader = PyPDFLoader(path)\n",
    "      documents = await ayncio.to_threat(loader.load)\n",
    "   else:\n",
    "      text_splitter = Recursive\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
