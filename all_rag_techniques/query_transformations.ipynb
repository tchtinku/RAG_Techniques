{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Transformations for Improved Retrieval in RAG Systems\n",
    "\n",
    "#### Overview\n",
    "\n",
    "###### This code implements three query transformation techniques to enhance the retrieval process in Retrieval-Augmented Generation (RAG) systems:\n",
    "\n",
    "###### 1. Query Rewriting\n",
    "###### 2. Step-back Prompting\n",
    "###### 3. Sub-query Decomposition\n",
    "\n",
    "###### Each technique aims to improve the relevance and comprehensiveness of retrieved information by modifying or expanding the original query\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "###### RAG systems often face challenges in retrieving the most relevant information, especially when dealing with complex or ambiguous queries. These query transformation techniques addresses this issue by reformulating queries to better match relevant documents or to retrieve more comprehensive information.\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "###### 1. Query  Rewriting: Reformulates queries to be more specific and detailed.\n",
    "###### 2. Step-back Prompting: Generates broader queries for better context retrieval.\n",
    "###### 3. Sub-query Decomposition: Breaks down complex queries into simpler sub-queries.\n",
    "\n",
    "#### Method Details\n",
    "\n",
    "##### 1. Query Rewriting\n",
    "###### Purpose: To make queries more specific and detailed, improving the likelihood of retrieving relevant information.\n",
    "###### Implementation:\n",
    "###### Uses a GPT-4 model with a custom prompt template\n",
    "###### Takes the original query and reformulates it to be more specific detailed.\n",
    "\n",
    "##### 2. Step-back Prompting\n",
    "###### Purpose: To generate broader, more general queries that can help retrieve relevant background information.\n",
    "###### Implementation:\n",
    "###### Uses a GPT-4 model with a custom prompt template\n",
    "###### Takes the original query and generates a more general \"step-back\" query.\n",
    "\n",
    "##### 3. Sub-query Decomposition\n",
    "###### Purpose: To break down complex queries into simpler sub-queries for more comprehensive information retrieval.\n",
    "###### Implementation:\n",
    "###### Uses a GPT-4 model with a custom prompt template\n",
    "###### Decomposes the original query into 2-4 simpler sub-queries\n",
    "\n",
    "#### Benefits of these Approaches\n",
    "###### Improved Relevance: Query rewriting helps in retrieving more specific and relevant information.\n",
    "###### Better Context: Step-back prompting allows for retrieval of broader context and background information.\n",
    "###### Comprehensive Results: Sub-query decomposition enables retrieval of information that covers different aspects of a complex query.\n",
    "###### Flexibility: Each technique can be used independently or in combination, depending on the specific use case.\n",
    "\n",
    "#### Implementation Details\n",
    "###### All techniques use OpenAI's GPT-4 model for query transformation.\n",
    "###### Custom prompt templates are used to guide the model in generating appropriate transformations.\n",
    "###### The code provides separate functions for each transformation technique, allowing for easy integration into existing RAG systems.\n",
    "\n",
    "###### Example Use Case\n",
    "###### The code demonstrates each technique using the example query: \"What are the impacts of climate change on the environment?\"\n",
    "\n",
    "###### Query Rewriting expands this to include specific aspects like temperature changes and biodiversity.\n",
    "###### Step-back Prompting generalizes it to \"What are the general effects of climate change?\"\n",
    "###### Sub-query Decomposition breaks it down into questions about biodiversity, oceans, weather patterns, and terrestrial environments.\n",
    "\n",
    "#### Conclusion\n",
    "###### These query transformation techniques offer powerful ways to enhance the retrieval capabilities of RAG systems. By reformulating queries in various ways, they can significantly improve the relevance, context, and comprehensiveness of retrieved information. These methods are particularly valuable in domains where queries can be complex or multifaceted, such as scientific research, legal analysis, or comprehensive fact-finding tasks.\n",
    "\n",
    "#### Import libraries and set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Load the environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Query Rewriting: Reformulating queries to improve retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "re_write_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "#Create a prompt template for query rewriting\n",
    "query_rewrite_template = \"\"\" You are an AI assistant tasked with formulating user queries to improve retrieval in a RAG system.\n",
    "Given the original query, rewrite it to be more specific, detailed and likely to retrieve relevant information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Rewritten query:\"\"\"\n",
    "\n",
    "query_rewrite_prompt = PromptTemplate(\n",
    "    input_variables = [\"original_query\"]\n",
    "    template = query_rewrite_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for query rewriting\n",
    "query_rewriter = query_rewrite_prompt | re_write_llm\n",
    "\n",
    "def rewrite_query(original_query):\n",
    "     \"\"\"\n",
    "     Rewrite the original query to improve retrieval.\n",
    "\n",
    "     Args:\n",
    "     original_query (str): The original user query\n",
    "\n",
    "     Returns:\n",
    "     str: The rewritten query\n",
    "     \"\"\"\n",
    "     response = query_rewriter.invoke(original_query)\n",
    "     return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_dataset = \"What are the impacts of climate change on the environment?\"\n",
    "rewritten_query = rewrite_query(original_query)\n",
    "print(\"Original Query:\", original_query)\n",
    "print(\"\\nRewritten query:\", rewritten_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Step-back Prompting: Generating broader queries for better context retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "step_back_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "\n",
    "# Create a prompt template for step-back prompting\n",
    "step_back_template = \"\"\"You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
    "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Step-back query:\"\"\"\n",
    "\n",
    "step_back_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=step_back_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for step-back prompting\n",
    "step_back_chain = step_back_prompt | step_back_llm\n",
    "\n",
    "def generate_step_back_query(original_query):\n",
    "    \"\"\"\n",
    "    Generate a step-back query to retrieve broader context.\n",
    "    \n",
    "    Args:\n",
    "    original_query (str): The original user query\n",
    "    \n",
    "    Returns:\n",
    "    str: The step-back query\n",
    "    \"\"\"\n",
    "    response = step_back_chain.invoke(original_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_dataset = \"What are the impacts of climate change on the environment?\"\n",
    "rewritten_query = generate_step_back_query(original_query)\n",
    "print(\"Original Query:\", original_query)\n",
    "print(\"\\nRewritten query:\", rewritten_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Sub-query Decomposition: Breaking complex queries into simpler sub-queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sub_query_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "\n",
    "# Create a prompt template for step-back prompting\n",
    "subquery_decomposition_template = \"\"\"You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
    "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Step-back query:\"\"\"\n",
    "\n",
    "subquery_decomposition_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=step_back_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for step-back prompting\n",
    "subquery_decomposition_chain = subquery_decomposition_prompt | sub_query_llm\n",
    "\n",
    "def decompose_query(original_query):\n",
    "    \"\"\"\n",
    "    Decompose the original query into simpler sub-queries\n",
    "    \n",
    "    Args:\n",
    "    original_query (str): The original user query\n",
    "    \n",
    "    Returns:\n",
    "    str: The step-back query\n",
    "    \"\"\"\n",
    "    response = subquery_decomposition_chain.invoke(original_query).content\n",
    "    sub_queries = [q.strip() for q in response.split('\\n') if q.strip() and not q.strip().startswith('Sub-queries:')]\n",
    "    return sub_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_query = \"What are the impacts of climate change on the environment?\"\n",
    "rewritten_query = decompose_query(original_query)\n",
    "print(\"\\nSub-queries:\")\n",
    "for i, sub_query in enumerate(sub_queries, 1):\n",
    "    print(sub_query)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
