{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPTOR: Recursive Abstractive Processing and Thematic Organization for Retrieval\n",
    "\n",
    "#### Overview\n",
    "\n",
    "###### RAPTOR is an advanced information retrieval and question-answering system that combines hierarchical document summarization, embedding-based retrieval, and contextual answer generation. It aims to efficiently handle large document collections by creating a multi-level tree of summaries, allowing for both broad and detailed information retrieval.\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "###### Traditional retrieval systems often struggle with large document sets, either missing important details or getting overwhelmed by irrelevant information. RAPTOR addresses this by creating a hierarchical structure of the document collection, allowing it to navigate between high-level concepts and specific details as needed.\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "###### 1. Tree Building: Creates a hierarchical structure of document summaries.\n",
    "###### 2.Embedding & Clustering: Organizes document and summaries based on semantic similarity.\n",
    "###### 3. Vectorstore: Efficiently stores and retrieves document and summary embeddings\n",
    "###### 4. Contextual Retriever: Selects the most relevant information for a given query.\n",
    "###### 5. Answer Generation: Produces coherent responses based on retrieved information\n",
    "\n",
    "#### Method Details\n",
    "\n",
    "##### Tree Building\n",
    "\n",
    "###### 1. Start with original documents at level 0.\n",
    "###### 2. For each level:\n",
    "######          -> Embed the texts using a language model\n",
    "######          -> Cluster the embeddings (e.g., using a Gaussian Mixture Models)\n",
    "######          -> Generate summaries for each cluster\n",
    "######          -> Use these summaries as the texts for the next level\n",
    "###### 3. Continue until reaching a single summary or a maximum level\n",
    "\n",
    "##### Embedding Retrieval\n",
    "\n",
    "###### 1. Embed all documents and summaries from all levels of the tree.\n",
    "###### 2. Store these embeeddings in a vectorstore (e.g, FAISS) for efficient similarity search.\n",
    "###### 3. For a given query:\n",
    "######        -> Embed the query\n",
    "######        -> Retrieve the most similar documents/summaries from the vectorstore\n",
    "\n",
    "##### Contextual Information\n",
    "\n",
    "###### 1. Take the retrieved document/summaries\n",
    "###### 2. Use a language model to extract only the most relevant parts for the given query.\n",
    "\n",
    "##### Answer Generation\n",
    "\n",
    "###### 1. Combine the relevant parts into a context.\n",
    "###### 2. Use a language model to generate an answer based on this context and the original query\n",
    "\n",
    "#### Benefits of this Approach\n",
    "\n",
    "###### 1. Scalability: Can handle large document collections by working with summaries at different levels\n",
    "###### 2. Flexibility: Capable of providing both high-level overviews and specific details.\n",
    "###### 3. Context-Awareness: Retrieves information from the most appropriate level of abstraction.\n",
    "###### 4. Efficiency: Uses embeddings and vectorstore for fast retrieval.\n",
    "###### 5. Traceability: Maintains link between summaries and original documents, allowing for source verification.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "###### RAPTOR represents a significant sdvancement in information retrieval and question-answering systems. By combining hierarchical summarization with embedding-based retrieval and contextual answer generation, it offers powerful & flexible approach to handle large document collections. The system's ability to navigate different levels of abstraction allows it to provide relevant & contextually appropriate answers to a wide range of queriess.\n",
    "\n",
    "###### While RAPTOR shows great promise, future work could focus on optimizing the tree-building process, improving summary quality, and enhancing the retrieval mechanism to better handle complex, multi-faceted queries. Additionally integrating this approach with other AI technologies could lead to even more sophisticated information processing syatems\n",
    "\n",
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema import AIMessage\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path since we work with notebooks\n",
    "from helper_functions import * \n",
    "from evaluation.evaluate_rag import *\n",
    "\n",
    "#Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Set the OpenAI API environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Logging, LLMs & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level = logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') \n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name = \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_text(item):\n",
    "    \"\"\"Extract text content from either a string or AIMessage object.\"\"\"\n",
    "    if isinstance(item, AIMessage):\n",
    "         return item.content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
